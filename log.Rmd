---
title: "Log"
author: "Carlo van Buiten"
date: "10/6/2021"
output: pdf_document
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(reshape2)
```

\newpage

# Research question
Is cell uniformity (shape and size) a good predictor for the malignancy of breast cancer?


In this dataset all attributes are grades ranging from 1 to 10, with 10 being the most severe. Each row is a unique case of breast-cancer. For specific percentages etc. refer to the user manual below:

Attributes definitions: https://www.rai-light.com/docs/BCD_User_Manual_v01.pdf


I hypothesize that it makes sense for a lower cell uniformity to coincide with a higher severity of (breast) cancer, since one the defining aspects of cancer is the erratic way the cells grow and multiply.




Let us start by taking a look at the data distribution.
```{r}
data <- read.csv("breast-cancer-wisconsin.data", na.strings="?")
colnames(data) <- c("id", "Clump_Thickness", "Cell_Size_Uniformity", "Cell_Shape_Uniformity", "Marginal_Adhesion",
                    "Single_Epithelial_Cell_Size", "Bare_Nuclei", "Bland_Chromatin", "Normal_Nucleoli", "Mitoses",
                    "Class")

# head(data, 10)
summary(data)
```
We can see the data does not follow a normal distribution, this becomes apparent when you compare the column means to the medians.


Let us take a look at the highest correlating features by only taking the data columns that correlate with malignancy for more than 80%.
```{r}
cor_data <- cor(data, use = "complete.obs")
cor_data <- as.data.frame(cor_data)
cor_cols <- names(cor_data)[which(cor_data$Class > 0.8)]
cor_cols 
```
There are 3 attributes that correlate with malignancy for more than 80%, 2 of which are pertaining to cell uniformity. This bodes well for the hypothesis that cell uniformity could potentially be a good predictor of malignant breast cancer.

Let us look at what the spreads of these attributes look like with regards to the 2 classes, where B is benign and M is malignant.

```{r}
plot_data <- data
plot_data$Class[plot_data$Class == 2] <- "B"
plot_data$Class[plot_data$Class == 4] <- "M"

ggplot(data=plot_data, mapping = aes(x = Class, y = Cell_Size_Uniformity)) +
  geom_jitter(width = 0.05, height = 0.3, col="red", alpha = 0.3) +
  labs(y="Cell Size Uniformity", 
       caption="Figure 1: Cell size uniformity spread per class.") +
  theme_minimal() +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0.5))
```

```{r}
ggplot(data=plot_data, mapping = aes(x = Class, y = Cell_Shape_Uniformity)) +
  geom_jitter(width = 0.05, height = 0.3, col="green", alpha = 0.3) +
  labs(y="Cell Shape Uniformity", 
       caption="Figure 2: Cell shape uniformity spread per class.") +
  theme_minimal() +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0.5))
```

```{r}
ggplot(data=plot_data, mapping = aes(x = Class, y = Bare_Nuclei)) +
  geom_jitter(width = 0.05, height = 0.3, col="blue", alpha = 0.3) +
  labs(y="Nuclei With Cytoplasm", 
       caption="Figure 3: Bare nuclei spread per class.") +
  theme_minimal() +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0.5))
```
It does seem to be the case that the more individual cells differ from each other (that is to say; being less uniform), the higher the chances are for the cancer to be malignant. The same goes for finding cytoplasm in the cell nucleus.
However, it looks like these 3 attributes correlate quite strongly not only with the class, but also with each other. It would make sense for cell shape and size uniformity to covariate, but let us actually compare each of these features with each other. 

```{r}
ggplot(data=plot_data, mapping = aes(x = Cell_Size_Uniformity, y = Cell_Shape_Uniformity)) +
  geom_jitter(width = 0.3, height = 0.3, alpha = 0.3, size = 0.5, aes(col=Class)) +
  geom_smooth(method = "lm", se = T) +
  labs(y="Cell Shape Uniformity", x="Cell Size Uniformity", 
       caption="Figure 4: Plot of the correlation between cell shape and size discrepancies") +
  theme_minimal() +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0.5))
```

Unsurprisingly, it does seem to be the case that the larger the differences in size between cells, the larger the differences in shapes as well. This makes sense as both these differences can be explained by erratic cell growth. Continuing to the other comparisons;


```{r}
ggplot(data=plot_data, mapping = aes(x = Cell_Size_Uniformity, y = Bare_Nuclei)) +
  geom_jitter(width = 0.3, height = 0.3, alpha = 0.3, size = 0.5, aes(col=Class)) +
  geom_smooth(method = "lm", se = T) +
  labs(y="Nuclei With Cytoplasm", x="Cell Size Uniformity", 
       caption="Figure 5: Plot of the correlation between nuclei with cytoplasm and cell size uniformity.") +
  theme_minimal() +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0.5))
```


```{r}
ggplot(data=plot_data, mapping = aes(x = Cell_Shape_Uniformity, y = Bare_Nuclei)) +
  geom_jitter(width = 0.3, height = 0.3, alpha = 0.3, size = 0.5, aes(col=Class)) +
  geom_smooth(method = "lm", se = T) +
  labs(y="Nuclei With Cytoplasm", x="Cell Shape Uniformity", 
       caption="Figure 6: Plot of the correlation between nuclei with cytoplasm and cell shape uniformity.") +
  theme_minimal() +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0.5))
```

The features that correlate less with the malignancy also seem to correlate slightly less amongst themselves, but let us make a heatmap of the entire dataset, to make sure we did not miss any other highly correlating attributes with our 80% cut-off.

```{r}
cor_matrix <- round(cor(na.omit(data[,-1])),2)
melted_cor_matrix <- melt(cor_matrix)

ggplot(data = melted_cor_matrix, aes(x=Var1, y=Var2, fill=value, )) + 
  geom_tile() +
  labs(y="", x="", 
       caption="Figure 7: Heatmap showing the correlations between all attributes.") +
  scale_fill_gradient(low="black", high="red") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 40, hjust = 1)) +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0.5))
```
We can clearly see cell uniformity and bare nuclei at the top, but it looks like all features correlate at least somewhat, with bland chromatin seemingly at the top of the sub-80% attributes with a correlation to class of roughly 76%. The heatmap also confirms the correlation between cell size and shape uniformity.

Having learnt this, let us now also make a graph of the spread for bland chromatin.

```{r}
ggplot(data=plot_data, mapping = aes(x = Class, y = Bland_Chromatin)) +
  geom_jitter(width = 0.05, height = 0.3, col="cyan", alpha = 0.3) +
  labs(y="Bland Chromatin", 
       caption="Figure 8: Bland Chromatin spread per class.") +
  theme_minimal() +
  theme(plot.caption.position = "plot",
        plot.caption = element_text(hjust = 0.5))
```

This seems to somewhat mimic the spreads of the top 3 correlating features, albeit to a slightly lesser degree. Take note that a grade of 10 on the bland chromatin attribute means that the chromatin is maximally coarse and a 1 stands for very finely textured chromatin.


There seem to be some duplicate entries in the data set, to remedy this I shall only take the unique rows.
```{r}
clean_data <- unique(plot_data)
```
It is important to get rid of duplicates like these, because they increase the weight of their corresponding attribute values.

As could be seen in the heatmap in figure 7, mitosis has by far the lowest correlation with malignancy and will therefore be removed from the data set. Aside from this, it is also unclear what "abnormal" mitosis means exactly.
As for the normal nucleoli attribute, its precise definition is unclear. A grade of 1, which is to say a "normal" nucleolus, is defined as being small and barely visible. There is zero clarification, however, of how a nucleolus starts to differ when looking at the higher grades. One can assume that there might then be multiple nucleoli, or they might be larger, but this is never quantified. I deem this too unclear and shall also remove this column from the data set. The ID column has no meaning and can also be removed.

```{r}
clean_data$Mitoses <- NULL
clean_data$Normal_Nucleoli <- NULL
clean_data$id <- NULL
clean_data <- na.omit(clean_data)
# Create new .csv file for use in WEKA
write.csv(clean_data, "clean_data.csv", row.names = FALSE)
```

When selecting a machine learning classifier for our specific problem, it is important to keep the weight false positives and negatives in mind. In our case, a false negative might result in a death that may otherwise have been prevented. But a false positive can result in a treatment of a perfectly healthy person that can severely reduce their quality of life. Both of these results can be equally devastating, but it might be prudent to err on the side of caution and preserve as many lives as possible by leaning ever so slightly in the positive direction when forced to make a decision.

### OneR:
93,0267% correctly classified instances.
11 false positives.
36 false negatives.

### VotedPerceptron:
90,9496% correctly classified instances.
48 false positives.
13 false negatives.

### NaiveBayes:
96.4392% correctly classified instances.
18 false positives.
6 false negatives.

### Logistic:
96.5875% correctly classified instances.
11 false positives.
12 false negatives.

### Bagging:
96.5875% correctly classified instances.
11 false positives.
12 false negatives.

Logistic and bagging are tied for the highest accuracy, it might be worth it to try both of these algorithms.

### CostSensitive Bagging (weighted 1.2 - 1):
96.2908% correctly classified instances.
16 false positives.
9 false negatives.

### CostSensitive Logistic (weighted 1.2 - 1):
96.7359% correctly classified instances.
11 false positives.
11 false negatives.

The accuracy seems to have improved, particularly for the logistic algorithm, but there are quite a few false negatives, something we wish to avoid.

### CostSensitive Logistic (weighted 4 - 1):
97.4777% correctly classified instances.
13 false positives.
4 false negatives.

By increasing the cost of false negatives even further we managed to increase the accuracy some more and reduce the amount of false negatives by 7, with the price of additional false positives.






